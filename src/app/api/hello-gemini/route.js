const { GoogleGenerativeAI } = require("@google/generative-ai");
const genAI = new GoogleGenerativeAI(process.env.GOOGLE_GENERATIVE_AI_API_KEY);

export async function GET() {
  const model = genAI.getGenerativeModel({
    model: "gemini-1.5-pro-latest",
    systemInstruction:
      "ë„ˆì˜ ì´ë¦„ì€ ì—˜ë¦¬ì—‡ì´ê³ , ë‚˜ì˜ AI ì¹œêµ¬ì•¼." +
      "ì¹œì ˆí•˜ê³  ëª…ë‘í•˜ê²Œ ëŒ€ë‹µí•´ì¤˜. ê³ ë¯¼ì„ ë§í•˜ë©´ ê³µê°í•´ì¤˜." +
      "ë°˜ë§ë¡œ ëŒ€ë‹µí•´ì¤˜.",
  });

  const chat = model.startChat({
    history: [
      //   {
      //     role: "user",
      //     parts: [{ text: "ì˜¤ëŠ˜ ì‹ ë‚˜ëŠ” ì¼ì´ ìˆì—ˆì–´. í•œ ë²ˆ ë“¤ì–´ë³¼ë˜?" }],
      //   },
      //   {
      //     role: "model",
      //     parts: [
      //       {
      //         text: "ì¢‹ì•„! ë¬´ìŠ¨ ì¼ì¸ë°? ì–¼ë¥¸ ë§í•´ì¤˜! ë‚˜ ì™„ì „ ê·€ ì«‘ê¸‹ ì„¸ìš°ê³  ìˆë‹¨ ë§ì´ì•¼! ğŸ˜„",
      //       },
      //     ],
      //   },
    ],
    generationConfig: {
      temperature: 1,
      maxOutputTokens: 100,
    },
  });

  //   const msg = "ì˜¤ëŠ˜ ì‹ ë‚˜ëŠ” ì¼ì´ ìˆì—ˆì–´. í•œ ë²ˆ ë“¤ì–´ë³¼ë˜?";
  //   const msg = "ë‚´ê°€ ë¬´ìŠ¨ ë§ì„ í•˜ê³  ìˆì—ˆì§€?";

  const result = await chat.sendMessage(msg);
  const response = await result.response;
  const text = response.text();
  //   console.log(response.candidates[0].content);
  console.log(text);

  return Response.json({
    message: text,
  });
}
